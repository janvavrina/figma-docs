services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - ./docs:/app/docs
      - ./config.yaml:/app/config.yaml
    environment:
      - FIGMA_API_TOKEN=${FIGMA_API_TOKEN}
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    networks:
      - figma-docs-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    networks:
      - figma-docs-network

  # Ollama - CPU version (no GPU)
  # For GPU support, use the commented section below
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - figma-docs-network
    # Healthcheck to ensure Ollama is ready
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s

  # Ollama model puller - pulls required models on startup
  ollama-pull:
    image: ollama/ollama:latest
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - figma-docs-network
    depends_on:
      ollama:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Pulling required models..."
        ollama pull gemma3:27b || echo "Failed to pull gemma3:27b"
        echo "Model pulling complete!"
    environment:
      - OLLAMA_HOST=ollama:11434

  # === GPU VERSION (NVIDIA) ===
  # Uncomment this section and comment out the CPU ollama service above
  # to use GPU acceleration with NVIDIA GPUs
  #
  # ollama:
  #   image: ollama/ollama:latest
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   networks:
  #     - figma-docs-network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 10s

networks:
  figma-docs-network:
    driver: bridge

volumes:
  ollama-data:
